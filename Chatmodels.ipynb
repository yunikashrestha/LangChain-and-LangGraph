{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6bef8711",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  WARNING: Failed to remove contents in a temporary directory 'C:\\Users\\Asus\\OneDrive\\Desktop\\Autolab_intern\\env_name\\Lib\\site-packages\\~rpc'.\n",
      "  You can safely remove it manually.\n",
      "\n",
      "[notice] A new release of pip is available: 24.2 -> 25.3\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "pip install -qU \"langchain[google-genai]\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a9c8d5e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import getpass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fb9351d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.environ.get(\"GOOGLE_API_KEY\"):\n",
    "    os.environ[\"GOOGLE_API_KEY\"]=getpass.getpass(\"Enter the API key for google gemini:\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "15bb5d27",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chat_models import init_chat_model\n",
    "model=init_chat_model(\"gemini-2.5-flash\",model_provider=\"google_genai\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b4b399ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LangChain is an open-source **framework** designed to help developers build applications powered by Large Language Models (LLMs). It provides a structured way to combine LLMs with other components to create more complex and capable applications than a standalone LLM could achieve.\n",
      "\n",
      "Think of it this way: LLMs are incredibly powerful \"brains,\" but they often need help with memory, accessing external knowledge, or performing specific actions. LangChain acts as the **orchestration layer** that connects the LLM brain to all these necessary \"limbs\" and \"senses.\"\n",
      "\n",
      "### Key Problems LangChain Solves:\n",
      "\n",
      "1.  **Limited Context Window:** LLMs can only remember a certain amount of conversation. LangChain helps integrate \"memory\" to maintain long-term context.\n",
      "2.  **Lack of External Knowledge:** LLMs are trained on a fixed dataset. LangChain enables them to access up-to-date information from the internet, databases, or custom documents.\n",
      "3.  **Inability to Perform Actions:** LLMs can generate text, but they can't natively perform actions like searching the web, running code, or calling APIs. LangChain provides \"tools\" for them to interact with the outside world.\n",
      "4.  **Complex Workflows:** Building multi-step interactions with LLMs (e.g., \"summarize this document, then answer a question about it, then email the answer\") is cumbersome. LangChain simplifies this with \"chains.\"\n",
      "5.  **Boilerplate Code:** Directly interacting with LLM APIs can involve a lot of repetitive code. LangChain abstracts much of this away.\n",
      "\n",
      "### Core Concepts and Components of LangChain:\n",
      "\n",
      "LangChain is built around several modular components that can be combined in various ways:\n",
      "\n",
      "1.  **Models:**\n",
      "    *   **LLMs:** Interface with various large language models (e.g., OpenAI's GPT series, Google's Gemini, Hugging Face models) for text generation.\n",
      "    *   **Chat Models:** Specifically designed for conversational interactions, handling message histories.\n",
      "    *   **Embeddings:** Generate numerical representations (embeddings) of text, crucial for semantic search and retrieval.\n",
      "\n",
      "2.  **Prompts:**\n",
      "    *   **Prompt Templates:** Standardized ways to construct prompts for LLMs, making it easy to include dynamic inputs and ensure consistent formatting.\n",
      "    *   **Output Parsers:** Extract structured information from the LLM's free-form text output (e.g., convert text to JSON, lists, or specific data types).\n",
      "\n",
      "3.  **Chains:**\n",
      "    *   The core concept where components are linked together in a sequence. A chain might involve:\n",
      "        *   Taking user input.\n",
      "        *   Formatting it with a prompt template.\n",
      "        *   Passing it to an LLM.\n",
      "        *   Parsing the LLM's output.\n",
      "        *   Passing that output to another LLM or tool.\n",
      "    *   Examples: `LLMChain`, `SequentialChain`, `RetrievalQAChain`.\n",
      "\n",
      "4.  **Retrieval:**\n",
      "    *   **Document Loaders:** Load data from various sources (PDFs, websites, databases).\n",
      "    *   **Text Splitters:** Break down large documents into smaller, manageable chunks.\n",
      "    *   **Vector Stores:** Store and search text embeddings, enabling semantic search and \"Retrieval Augmented Generation\" (RAG) where relevant information is retrieved from a knowledge base before being passed to the LLM.\n",
      "\n",
      "5.  **Memory:**\n",
      "    *   Allows an LLM application to remember past interactions in a conversation. Different types of memory exist (e.g., `ConversationBufferMemory`, `ConversationSummaryMemory`).\n",
      "\n",
      "6.  **Agents:**\n",
      "    *   The most dynamic and powerful component. Agents use an LLM as a \"reasoning engine\" to decide *which tools to use and in what order* to achieve a specific goal.\n",
      "    *   They can perform actions, observe the results, and then decide on the next step, creating a dynamic problem-solving loop.\n",
      "    *   **Tools:** External utilities that agents can use (e.g., a search engine, a calculator, a custom API call, a Python interpreter).\n",
      "\n",
      "### What Can You Build with LangChain?\n",
      "\n",
      "*   **Advanced Chatbots:** That remember conversation history, access up-to-date information, and perform actions.\n",
      "*   **Question-Answering Systems:** Over custom documents (e.g., your company's internal knowledge base, legal documents, research papers).\n",
      "*   **Autonomous Agents:** That can plan and execute multi-step tasks.\n",
      "*   **Data Extraction Tools:** To pull structured information from unstructured text.\n",
      "*   **Summarization and Content Generation:** With access to external data.\n",
      "*   **Code Generation Assistants:** That can use tools like a Python interpreter to test code.\n",
      "\n",
      "### Benefits of Using LangChain:\n",
      "\n",
      "*   **Modularity:** Easily swap out different LLMs, tools, and components.\n",
      "*   **Extensibility:** Simple to integrate custom tools, data sources, and models.\n",
      "*   **Reduced Complexity:** Abstracts away much of the boilerplate code for LLM interactions.\n",
      "*   **Rapid Prototyping:** Quickly build and test complex LLM applications.\n",
      "*   **Enables Advanced Use Cases:** Makes capabilities like RAG and agentic behavior much more accessible.\n",
      "\n",
      "In essence, LangChain empowers developers to move beyond simple LLM prompts and build sophisticated, context-aware, and interactive applications that leverage the full potential of large language models.\n"
     ]
    }
   ],
   "source": [
    "response=model.invoke(\"What is Langchain\")\n",
    "print(response.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ebd2a83",
   "metadata": {},
   "source": [
    "#### Creating basic agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c4a722f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.agents import create_agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4d28f28b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_weather(city:str)->str:\n",
    "    \"\"\" Get weather for a given city.\"\"\"\n",
    "\n",
    "    return f\"It is cloudy in {city}\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "75355bb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "agent=create_agent(\n",
    "    model=model,\n",
    "    tools=[get_weather],\n",
    "    system_prompt=\"You are a helpful assistant\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b1e0d4ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "response1=agent.invoke(\n",
    "    {\"messages\":[{\"role\":\"user\",\"content\":\"What is weather in Nepal\"}]}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "cf2b907f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'messages': [HumanMessage(content='What is weather in Nepal', additional_kwargs={}, response_metadata={}, id='5ffe6958-2998-4753-bb92-92ddbf1c7c99'), AIMessage(content=[{'type': 'text', 'text': 'Nepal is a country. I need a specific city to get the weather. Can you please tell me a city in Nepal?', 'extras': {'signature': 'CpcFAdHtim/WUg8XwPdRYd5H4VgKLR+1E4qNOVu5pc3gm0CZT/ZuyHX2/hR0g9Ogq2QXEIE+jrCT5ceDZYGRS0x/R8VT2oN9BS7htcUWiMC/LM7CnUI0TCj5cSMg3JE96FR31EeS46sOBxDBP2cjWKVwhaU0e8CSGPWj7O0yU6uWmmc/nZJfGvPjsdfjtV24QTwtdA37TE0/KC5VZgNKovg93h5CpTGlzHV7+yK5AWnARbbjtXpgrLlCG5A7bgEvrlAkl6aRCk0Y+85Z8T+HJ5JX18yf35i++xc3jA/UNb1hZhbOX9hul5cy6JkeUMJW3gv/E6bU/XwbZGmzC3jN4vNEc11VW5xdd6Dv2SsKfnldiLQQJ2zNyNaB/taDaktkeRWlpSuC712CSzoXQXpka+tb281pzMopj58vi9g8G1gFDV/FvzXU3smUREVcETjW3AHBK41Y8XvtMFOmouzIcbYwDvPzlB7S4k3Rp35EOctethWJ02D+S4WM2g1uNHBpwF22AQs0bdkVCvWLuqBbD6N2fRqSfwT6IHVVf85cDlCWt64evYqZUYT6I3yI3FT2GxsEJMrv/HUoEcYRC/VmKVP/ZDN1YghqiTrkKbEL42Y7CEWyIBkrJoFB6GE+x3/Ub9OC3zb1mYnozdVkVaev0i9Z4vuIF/4J4UZ1XhlP4zuHQAyGS+Hh6VxXwijbdibkGooPB2IgHP7onMOb6LRvMqrj/vuNmDfMbzLDgh5zqgbdEac9epLki7Qithfya6KD6IDDGIAs3f1mUoZjg/L4GeqzB47mTEJhsrfqXp4FkcuAkYBljSVJvc7r90RtLB3aF74Y3FLI0FKCklIpm1UUyqsaqDncxt4cwDi16V6vLDZYSBrjkoYXns/2'}}], additional_kwargs={}, response_metadata={'prompt_feedback': {'block_reason': 0, 'safety_ratings': []}, 'finish_reason': 'STOP', 'model_name': 'gemini-2.5-flash', 'safety_ratings': [], 'grounding_metadata': {}, 'model_provider': 'google_genai'}, id='lc_run--e10ce744-78b0-454e-8374-1982dfe95e41-0', usage_metadata={'input_tokens': 50, 'output_tokens': 180, 'total_tokens': 230, 'input_token_details': {'cache_read': 0}, 'output_token_details': {'reasoning': 155}})]}\n"
     ]
    }
   ],
   "source": [
    "print(response1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e99dc5f5",
   "metadata": {},
   "source": [
    "#### Using Language Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ec8fb45c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "content=\"**おはようございます** (Ohayō gozaimasu)\\n\\n*   **おはよう** (Ohayō) is also used, but it's more casual, typically among family, close friends, or colleagues in the same team/department.\\n*   **おはようございます** (Ohayō gozaimasu) is the polite and standard form, appropriate for most situations.\" additional_kwargs={} response_metadata={'prompt_feedback': {'block_reason': 0, 'safety_ratings': []}, 'finish_reason': 'STOP', 'model_name': 'gemini-2.5-flash', 'safety_ratings': [], 'grounding_metadata': {}, 'model_provider': 'google_genai'} id='lc_run--37ea3965-62f6-4012-839f-64f89455277d-0' usage_metadata={'input_tokens': 11, 'output_tokens': 151, 'total_tokens': 162, 'input_token_details': {'cache_read': 0}, 'output_token_details': {'reasoning': 72}}\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.messages import HumanMessage,SystemMessage\n",
    "\n",
    "message=[\n",
    "    SystemMessage(content=\"Translate the sentence from English to Japnese\"),\n",
    "    HumanMessage(content=\"Good morning\")\n",
    "]\n",
    "res=model.invoke(message)\n",
    "print(res)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02b4f2a3",
   "metadata": {},
   "source": [
    "#### Prompt Template\n",
    " take in raw user input and return data (a prompt) that is ready to pass into a language model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "45b26bcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "system_template=\"Translate te following from English to {language}\"\n",
    "prompt_template=ChatPromptTemplate.from_messages([(\"system\",system_template),(\"user\",\"{text}\")])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "7dbfead4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatPromptValue(messages=[SystemMessage(content='Translate te following from English to Korean', additional_kwargs={}, response_metadata={}), HumanMessage(content='hi', additional_kwargs={}, response_metadata={})])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt=prompt_template.invoke({\"language\":\"Korean\",\"text\":\"hi\"})\n",
    "prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "f138357e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "content='안녕하세요 (annyeonghaseyo)' additional_kwargs={} response_metadata={'prompt_feedback': {'block_reason': 0, 'safety_ratings': []}, 'finish_reason': 'STOP', 'model_name': 'gemini-2.5-flash', 'safety_ratings': [], 'grounding_metadata': {}, 'model_provider': 'google_genai'} id='lc_run--d27b97d5-5563-49df-bdbd-676a5581a822-0' usage_metadata={'input_tokens': 9, 'output_tokens': 43, 'total_tokens': 52, 'input_token_details': {'cache_read': 0}, 'output_token_details': {'reasoning': 36}}\n"
     ]
    }
   ],
   "source": [
    "res=model.invoke(prompt)\n",
    "print(res)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bc37f30",
   "metadata": {},
   "source": [
    "## Semantic Seach Engine"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a89570b0",
   "metadata": {},
   "source": [
    "#### Document Loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "df60b380",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting langchain-community\n",
      "  Downloading langchain_community-0.4.1-py3-none-any.whl.metadata (3.0 kB)\n",
      "Collecting pypdf\n",
      "  Downloading pypdf-6.1.3-py3-none-any.whl.metadata (7.1 kB)\n",
      "Requirement already satisfied: langchain-core<2.0.0,>=1.0.1 in c:\\users\\asus\\onedrive\\desktop\\autolab_intern\\env_name\\lib\\site-packages (from langchain-community) (1.0.1)\n",
      "Collecting langchain-classic<2.0.0,>=1.0.0 (from langchain-community)\n",
      "  Downloading langchain_classic-1.0.0-py3-none-any.whl.metadata (3.9 kB)\n",
      "Collecting SQLAlchemy<3.0.0,>=1.4.0 (from langchain-community)\n",
      "  Downloading sqlalchemy-2.0.44-cp312-cp312-win_amd64.whl.metadata (9.8 kB)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.32.5 in c:\\users\\asus\\onedrive\\desktop\\autolab_intern\\env_name\\lib\\site-packages (from langchain-community) (2.32.5)\n",
      "Requirement already satisfied: PyYAML<7.0.0,>=5.3.0 in c:\\users\\asus\\onedrive\\desktop\\autolab_intern\\env_name\\lib\\site-packages (from langchain-community) (6.0.2)\n",
      "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in c:\\users\\asus\\onedrive\\desktop\\autolab_intern\\env_name\\lib\\site-packages (from langchain-community) (3.12.15)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in c:\\users\\asus\\onedrive\\desktop\\autolab_intern\\env_name\\lib\\site-packages (from langchain-community) (9.1.2)\n",
      "Collecting dataclasses-json<0.7.0,>=0.6.7 (from langchain-community)\n",
      "  Downloading dataclasses_json-0.6.7-py3-none-any.whl.metadata (25 kB)\n",
      "Collecting pydantic-settings<3.0.0,>=2.10.1 (from langchain-community)\n",
      "  Downloading pydantic_settings-2.11.0-py3-none-any.whl.metadata (3.4 kB)\n",
      "Requirement already satisfied: langsmith<1.0.0,>=0.1.125 in c:\\users\\asus\\onedrive\\desktop\\autolab_intern\\env_name\\lib\\site-packages (from langchain-community) (0.4.38)\n",
      "Collecting httpx-sse<1.0.0,>=0.4.0 (from langchain-community)\n",
      "  Downloading httpx_sse-0.4.3-py3-none-any.whl.metadata (9.7 kB)\n",
      "Requirement already satisfied: numpy>=1.26.2 in c:\\users\\asus\\onedrive\\desktop\\autolab_intern\\env_name\\lib\\site-packages (from langchain-community) (2.3.3)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in c:\\users\\asus\\onedrive\\desktop\\autolab_intern\\env_name\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (2.6.1)\n",
      "Requirement already satisfied: aiosignal>=1.4.0 in c:\\users\\asus\\onedrive\\desktop\\autolab_intern\\env_name\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.4.0)\n",
      "Requirement already satisfied: attrs>=17.3.0 in c:\\users\\asus\\onedrive\\desktop\\autolab_intern\\env_name\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (25.3.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in c:\\users\\asus\\onedrive\\desktop\\autolab_intern\\env_name\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.7.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in c:\\users\\asus\\onedrive\\desktop\\autolab_intern\\env_name\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (6.6.4)\n",
      "Requirement already satisfied: propcache>=0.2.0 in c:\\users\\asus\\onedrive\\desktop\\autolab_intern\\env_name\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (0.3.2)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in c:\\users\\asus\\onedrive\\desktop\\autolab_intern\\env_name\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.20.1)\n",
      "Collecting marshmallow<4.0.0,>=3.18.0 (from dataclasses-json<0.7.0,>=0.6.7->langchain-community)\n",
      "  Downloading marshmallow-3.26.1-py3-none-any.whl.metadata (7.3 kB)\n",
      "Collecting typing-inspect<1,>=0.4.0 (from dataclasses-json<0.7.0,>=0.6.7->langchain-community)\n",
      "  Downloading typing_inspect-0.9.0-py3-none-any.whl.metadata (1.5 kB)\n",
      "Requirement already satisfied: langchain-text-splitters<2.0.0,>=1.0.0 in c:\\users\\asus\\onedrive\\desktop\\autolab_intern\\env_name\\lib\\site-packages (from langchain-classic<2.0.0,>=1.0.0->langchain-community) (1.0.0)\n",
      "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in c:\\users\\asus\\onedrive\\desktop\\autolab_intern\\env_name\\lib\\site-packages (from langchain-classic<2.0.0,>=1.0.0->langchain-community) (2.11.9)\n",
      "Requirement already satisfied: jsonpatch<2.0.0,>=1.33.0 in c:\\users\\asus\\onedrive\\desktop\\autolab_intern\\env_name\\lib\\site-packages (from langchain-core<2.0.0,>=1.0.1->langchain-community) (1.33)\n",
      "Requirement already satisfied: packaging<26.0.0,>=23.2.0 in c:\\users\\asus\\onedrive\\desktop\\autolab_intern\\env_name\\lib\\site-packages (from langchain-core<2.0.0,>=1.0.1->langchain-community) (25.0)\n",
      "Requirement already satisfied: typing-extensions<5.0.0,>=4.7.0 in c:\\users\\asus\\onedrive\\desktop\\autolab_intern\\env_name\\lib\\site-packages (from langchain-core<2.0.0,>=1.0.1->langchain-community) (4.15.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in c:\\users\\asus\\onedrive\\desktop\\autolab_intern\\env_name\\lib\\site-packages (from langsmith<1.0.0,>=0.1.125->langchain-community) (0.28.1)\n",
      "Requirement already satisfied: orjson>=3.9.14 in c:\\users\\asus\\onedrive\\desktop\\autolab_intern\\env_name\\lib\\site-packages (from langsmith<1.0.0,>=0.1.125->langchain-community) (3.11.4)\n",
      "Requirement already satisfied: requests-toolbelt>=1.0.0 in c:\\users\\asus\\onedrive\\desktop\\autolab_intern\\env_name\\lib\\site-packages (from langsmith<1.0.0,>=0.1.125->langchain-community) (1.0.0)\n",
      "Requirement already satisfied: zstandard>=0.23.0 in c:\\users\\asus\\onedrive\\desktop\\autolab_intern\\env_name\\lib\\site-packages (from langsmith<1.0.0,>=0.1.125->langchain-community) (0.25.0)\n",
      "Requirement already satisfied: python-dotenv>=0.21.0 in c:\\users\\asus\\onedrive\\desktop\\autolab_intern\\env_name\\lib\\site-packages (from pydantic-settings<3.0.0,>=2.10.1->langchain-community) (1.1.1)\n",
      "Requirement already satisfied: typing-inspection>=0.4.0 in c:\\users\\asus\\onedrive\\desktop\\autolab_intern\\env_name\\lib\\site-packages (from pydantic-settings<3.0.0,>=2.10.1->langchain-community) (0.4.1)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in c:\\users\\asus\\onedrive\\desktop\\autolab_intern\\env_name\\lib\\site-packages (from requests<3.0.0,>=2.32.5->langchain-community) (3.4.3)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\asus\\onedrive\\desktop\\autolab_intern\\env_name\\lib\\site-packages (from requests<3.0.0,>=2.32.5->langchain-community) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\asus\\onedrive\\desktop\\autolab_intern\\env_name\\lib\\site-packages (from requests<3.0.0,>=2.32.5->langchain-community) (2.5.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\asus\\onedrive\\desktop\\autolab_intern\\env_name\\lib\\site-packages (from requests<3.0.0,>=2.32.5->langchain-community) (2025.8.3)\n",
      "Requirement already satisfied: greenlet>=1 in c:\\users\\asus\\onedrive\\desktop\\autolab_intern\\env_name\\lib\\site-packages (from SQLAlchemy<3.0.0,>=1.4.0->langchain-community) (3.2.4)\n",
      "Requirement already satisfied: anyio in c:\\users\\asus\\onedrive\\desktop\\autolab_intern\\env_name\\lib\\site-packages (from httpx<1,>=0.23.0->langsmith<1.0.0,>=0.1.125->langchain-community) (4.10.0)\n",
      "Requirement already satisfied: httpcore==1.* in c:\\users\\asus\\onedrive\\desktop\\autolab_intern\\env_name\\lib\\site-packages (from httpx<1,>=0.23.0->langsmith<1.0.0,>=0.1.125->langchain-community) (1.0.9)\n",
      "Requirement already satisfied: h11>=0.16 in c:\\users\\asus\\onedrive\\desktop\\autolab_intern\\env_name\\lib\\site-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith<1.0.0,>=0.1.125->langchain-community) (0.16.0)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in c:\\users\\asus\\onedrive\\desktop\\autolab_intern\\env_name\\lib\\site-packages (from jsonpatch<2.0.0,>=1.33.0->langchain-core<2.0.0,>=1.0.1->langchain-community) (3.0.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in c:\\users\\asus\\onedrive\\desktop\\autolab_intern\\env_name\\lib\\site-packages (from pydantic<3.0.0,>=2.7.4->langchain-classic<2.0.0,>=1.0.0->langchain-community) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.33.2 in c:\\users\\asus\\onedrive\\desktop\\autolab_intern\\env_name\\lib\\site-packages (from pydantic<3.0.0,>=2.7.4->langchain-classic<2.0.0,>=1.0.0->langchain-community) (2.33.2)\n",
      "Collecting mypy-extensions>=0.3.0 (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7.0,>=0.6.7->langchain-community)\n",
      "  Downloading mypy_extensions-1.1.0-py3-none-any.whl.metadata (1.1 kB)\n",
      "Requirement already satisfied: sniffio>=1.1 in c:\\users\\asus\\onedrive\\desktop\\autolab_intern\\env_name\\lib\\site-packages (from anyio->httpx<1,>=0.23.0->langsmith<1.0.0,>=0.1.125->langchain-community) (1.3.1)\n",
      "Downloading langchain_community-0.4.1-py3-none-any.whl (2.5 MB)\n",
      "   ---------------------------------------- 0.0/2.5 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.0/2.5 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.0/2.5 MB ? eta -:--:--\n",
      "   ---- ----------------------------------- 0.3/2.5 MB ? eta -:--:--\n",
      "   -------- ------------------------------- 0.5/2.5 MB 840.2 kB/s eta 0:00:03\n",
      "   -------- ------------------------------- 0.5/2.5 MB 840.2 kB/s eta 0:00:03\n",
      "   ------------ --------------------------- 0.8/2.5 MB 932.9 kB/s eta 0:00:02\n",
      "   ---------------- ----------------------- 1.0/2.5 MB 988.0 kB/s eta 0:00:02\n",
      "   -------------------- ------------------- 1.3/2.5 MB 959.4 kB/s eta 0:00:02\n",
      "   ------------------------ --------------- 1.6/2.5 MB 999.0 kB/s eta 0:00:01\n",
      "   ---------------------------- ----------- 1.8/2.5 MB 1.0 MB/s eta 0:00:01\n",
      "   ---------------------------- ----------- 1.8/2.5 MB 1.0 MB/s eta 0:00:01\n",
      "   --------------------------------- ------ 2.1/2.5 MB 978.7 kB/s eta 0:00:01\n",
      "   ------------------------------------- -- 2.4/2.5 MB 958.9 kB/s eta 0:00:01\n",
      "   ---------------------------------------- 2.5/2.5 MB 950.3 kB/s eta 0:00:00\n",
      "Downloading pypdf-6.1.3-py3-none-any.whl (323 kB)\n",
      "Downloading dataclasses_json-0.6.7-py3-none-any.whl (28 kB)\n",
      "Downloading httpx_sse-0.4.3-py3-none-any.whl (9.0 kB)\n",
      "Downloading langchain_classic-1.0.0-py3-none-any.whl (1.0 MB)\n",
      "   ---------------------------------------- 0.0/1.0 MB ? eta -:--:--\n",
      "   ---------- ----------------------------- 0.3/1.0 MB ? eta -:--:--\n",
      "   ---------- ----------------------------- 0.3/1.0 MB ? eta -:--:--\n",
      "   -------------------- ------------------- 0.5/1.0 MB 1.2 MB/s eta 0:00:01\n",
      "   ------------------------------ --------- 0.8/1.0 MB 1.1 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 1.0/1.0 MB 1.2 MB/s eta 0:00:00\n",
      "Downloading pydantic_settings-2.11.0-py3-none-any.whl (48 kB)\n",
      "Downloading sqlalchemy-2.0.44-cp312-cp312-win_amd64.whl (2.1 MB)\n",
      "   ---------------------------------------- 0.0/2.1 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.0/2.1 MB ? eta -:--:--\n",
      "   --------- ------------------------------ 0.5/2.1 MB 1.9 MB/s eta 0:00:01\n",
      "   -------------- ------------------------- 0.8/2.1 MB 1.5 MB/s eta 0:00:01\n",
      "   ------------------- -------------------- 1.0/2.1 MB 1.5 MB/s eta 0:00:01\n",
      "   ------------------------ --------------- 1.3/2.1 MB 1.4 MB/s eta 0:00:01\n",
      "   ----------------------------- ---------- 1.6/2.1 MB 1.3 MB/s eta 0:00:01\n",
      "   ---------------------------------- ----- 1.8/2.1 MB 1.3 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 2.1/2.1 MB 1.4 MB/s eta 0:00:00\n",
      "Downloading marshmallow-3.26.1-py3-none-any.whl (50 kB)\n",
      "Downloading typing_inspect-0.9.0-py3-none-any.whl (8.8 kB)\n",
      "Downloading mypy_extensions-1.1.0-py3-none-any.whl (5.0 kB)\n",
      "Installing collected packages: SQLAlchemy, pypdf, mypy-extensions, marshmallow, httpx-sse, typing-inspect, pydantic-settings, dataclasses-json, langchain-classic, langchain-community\n",
      "Successfully installed SQLAlchemy-2.0.44 dataclasses-json-0.6.7 httpx-sse-0.4.3 langchain-classic-1.0.0 langchain-community-0.4.1 marshmallow-3.26.1 mypy-extensions-1.1.0 pydantic-settings-2.11.0 pypdf-6.1.3 typing-inspect-0.9.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.2 -> 25.3\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "pip install langchain-community pypdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "45a6f97e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    }
   ],
   "source": [
    "from langchain_community.document_loaders import PyPDFLoader\n",
    "file_path=\"basic-text.pdf\"\n",
    "loader=PyPDFLoader(file_path)\n",
    "docs=loader.load()\n",
    "print(len(docs))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "69e9e14d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample Document for PDF Testing\n",
      "Introduction\n",
      "This is a simple document created to test basic PDF functionality. It includes various text formatting\n",
      "options to ensure proper rendering in PDF readers.\n",
      "T\n",
      "{'producer': 'Skia/PDF m126', 'creator': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/126.0.0.0 Safari/537.36', 'creationdate': '2024-07-09T13:31:41+00:00', 'title': 'Sample Document for PDF Testing', 'moddate': '2024-07-09T13:31:41+00:00', 'source': 'basic-text.pdf', 'total_pages': 1, 'page': 0, 'page_label': '1'}\n"
     ]
    }
   ],
   "source": [
    "print(f\"{docs[0].page_content[:200]}\")\n",
    "print(f\"{docs[0].metadata}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bef4acd",
   "metadata": {},
   "source": [
    "#### Splitter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "065edef5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "splitter=RecursiveCharacterTextSplitter(chunk_size=100,chunk_overlap=10,add_start_index=True)\n",
    "all_splits=splitter.split_documents(docs)\n",
    "len(all_splits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "b2d5dc9d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Document(metadata={'producer': 'Skia/PDF m126', 'creator': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/126.0.0.0 Safari/537.36', 'creationdate': '2024-07-09T13:31:41+00:00', 'title': 'Sample Document for PDF Testing', 'moddate': '2024-07-09T13:31:41+00:00', 'source': 'basic-text.pdf', 'total_pages': 1, 'page': 0, 'page_label': '1', 'start_index': 410}, page_content=\"Item 1\\nItem 2\\nItem 3\\nAnd here's an ordered list:\\n1. First item\\n2. Second item\\n3. Third item\\nQuote\")"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_splits[6]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ddd81eb",
   "metadata": {},
   "source": [
    "#### Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "5eced800",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.2 -> 25.3\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "pip install -qU langchain-google-genai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "4f712056",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_google_genai import GoogleGenerativeAIEmbeddings\n",
    "embeddings=GoogleGenerativeAIEmbeddings(model=\"models/gemini-embedding-001\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "252be393",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3072\n"
     ]
    }
   ],
   "source": [
    "vector_1=embeddings.embed_query(all_splits[0].page_content)\n",
    "vector_2=embeddings.embed_query(all_splits[1].page_content)\n",
    "\n",
    "print(len(vector_1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "85e6b07e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.009608505293726921, -0.005367163568735123, 0.015974808484315872, -0.07413351535797119, -0.0062061939388513565, 0.012328092940151691, 0.011254881508648396, -0.016206800937652588, 0.0011252409312874079, 0.01037000585347414]\n"
     ]
    }
   ],
   "source": [
    "print(vector_1[:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74fcf229",
   "metadata": {},
   "source": [
    "#### Vector Storage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "67e4aede",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.2 -> 25.3\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "pip install -qU langchain-qdrant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "f5badae8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_qdrant import QdrantVectorStore\n",
    "from qdrant_client import QdrantClient\n",
    "from qdrant_client.models import Distance,VectorParams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "8e10a564",
   "metadata": {},
   "outputs": [],
   "source": [
    "client=QdrantClient(\"http://localhost:6333\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "e38ec026",
   "metadata": {},
   "outputs": [],
   "source": [
    "vector_size=len(embeddings.embed_query(\"sample text\"))\n",
    "if not client.collection_exists(\"test\"):\n",
    "    client.create_collection(\n",
    "        collection_name=\"test\",\n",
    "        vectors_config=VectorParams(size=vector_size,distance=Distance.COSINE)\n",
    "    )\n",
    "vector_store=QdrantVectorStore(\n",
    "        client=client,\n",
    "        collection_name=\"test\",\n",
    "        embedding=embeddings,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "89a6b3a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "ids=vector_store.add_documents(documents=all_splits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "a291c6ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "page_content='This sample PDF file is provided by Sample-Files.com. Visit us for more sample files and resources.' metadata={'producer': 'Skia/PDF m126', 'creator': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/126.0.0.0 Safari/537.36', 'creationdate': '2024-07-09T13:31:41+00:00', 'title': 'Sample Document for PDF Testing', 'moddate': '2024-07-09T13:31:41+00:00', 'source': 'basic-text.pdf', 'total_pages': 1, 'page': 0, 'page_label': '1', 'start_index': 816, '_id': '28175c60-a67f-472e-97aa-8e0366c34596', '_collection_name': 'test'}\n"
     ]
    }
   ],
   "source": [
    "res=vector_store.similarity_search(\"What is this pdf about?\")\n",
    "print(res[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "b28b2c21",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "page_content='This sample PDF file is provided by Sample-Files.com. Visit us for more sample files and resources.' metadata={'producer': 'Skia/PDF m126', 'creator': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/126.0.0.0 Safari/537.36', 'creationdate': '2024-07-09T13:31:41+00:00', 'title': 'Sample Document for PDF Testing', 'moddate': '2024-07-09T13:31:41+00:00', 'source': 'basic-text.pdf', 'total_pages': 1, 'page': 0, 'page_label': '1', 'start_index': 816, '_id': '28175c60-a67f-472e-97aa-8e0366c34596', '_collection_name': 'test'}\n"
     ]
    }
   ],
   "source": [
    "res = await vector_store.asimilarity_search(\"What is this pdf about?\")\n",
    "\n",
    "print(res[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63b21dde",
   "metadata": {},
   "source": [
    "### Building weather agent"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env_name (3.12.7)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
